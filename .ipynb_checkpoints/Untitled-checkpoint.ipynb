{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from gym.spaces import Box, Discrete\n",
    "import tensorflow as tf\n",
    "from baseline.LinearBaseline import *\n",
    "from utils import *\n",
    "from policy.multilayerNN_policy import MultiLayerNN_Policy\n",
    "from cartpole_optimizer import CartPole_Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "scope = 'ppap'\n",
    "env = gym.make('CartPole-v0')\n",
    "ob_dim, n_acts = get_space_size(env)\n",
    "NN_config = {\n",
    "\t'in': ob_dim, \\\n",
    "\t'hidden_1': 8, \\\n",
    "\t'out': n_acts \\\n",
    "}\n",
    "p = MultiLayerNN_Policy(session=sess, optimizer=opt, scope=scope, NN_config=NN_config)\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "train_config = {\n",
    "\t'max_iters': 1, \\\n",
    "\t'n_episodes': 20, \\\n",
    "\t'path_max_len': 10, \\\n",
    "\t'thresh': 150 \\\n",
    "}\n",
    "opt = CartPole_Optimizer(p, env, train_config)\n",
    "opt.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-10-13 15:45:20,327] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "# env = gym.make('MountainCar-v0')\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space = env.observation_space\n",
    "np.prod(space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ob, r, done, _ = env.step(env.action_space.sample())\n",
    "print(ob)\n",
    "print(r)\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(ob)\n",
    "print(r)\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_path(env, policy, path_len):\n",
    "    obs = []\n",
    "    rewards = []\n",
    "    actions = []\n",
    "    ob = env.reset() # initial observation\n",
    "    \n",
    "    for _ in xrange(path_len):\n",
    "        act = policy.sample() # take an action according to policy\n",
    "        next_ob, r, done, _ = env.step(act) \n",
    "        # do \"act\" response to \"ob\" and get \"r\" as reward\n",
    "        obs.append(ob)\n",
    "        rewards.append(r)\n",
    "        actions.append(act)        \n",
    "        # next_ob is the observation after current \"act\" is done\n",
    "        ob = next_ob\n",
    "        # path terminates\n",
    "        if done:\n",
    "            break\n",
    "    return {\n",
    "        'observations': np.array(obs), \n",
    "        'rewards': np.array(rewards), \n",
    "        'actions': np.array(actions)\n",
    "    }      \n",
    "#     return dict( \n",
    "#         observations = np.array(obs), \n",
    "#         rewards = np.array(rewards), \n",
    "#         actions = np.array(actions)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "policy = env.action_space # randomly sample action\n",
    "paths = sample_path(env, policy, 10)\n",
    "paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class papa(object):\n",
    "    def __init__(self):\n",
    "        self._x = 0\n",
    "        \n",
    "    def act(self):\n",
    "        print('take papa action')\n",
    "        \n",
    "    @property\n",
    "    def x(self):\n",
    "        return self._x\n",
    "    def __str__(self):\n",
    "        return 'This is papa'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class son_1(papa):\n",
    "    def __init__(self, a):\n",
    "        papa.__init__(self)\n",
    "        self._a = a\n",
    "    def __str__(self):\n",
    "        return 'This is son_1'\n",
    "        \n",
    "    def act(self):\n",
    "        print('take son_1 action')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s1 = son_1(2)\n",
    "print(s1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s1_cand = papa()\n",
    "s1_cand._x = 1\n",
    "print(s1_cand.x)\n",
    "s1 = son_1(s1_cand)\n",
    "print(s1.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from policy.MultiLayerNN_Policy import MultiLayerNN_Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy\n",
      "policy/observation\n",
      "policy/actions\n",
      "policy/advantages\n",
      "policy/nn/hidden_1/weights\n",
      "policy/nn/hidden_1/weights/Initializer/random_normal/shape\n",
      "policy/nn/hidden_1/weights/Initializer/random_normal/mean\n",
      "policy/nn/hidden_1/weights/Initializer/random_normal/stddev\n",
      "policy/nn/hidden_1/weights/Initializer/random_normal/RandomStandardNormal\n",
      "policy/nn/hidden_1/weights/Initializer/random_normal/mul\n",
      "policy/nn/hidden_1/weights/Initializer/random_normal\n",
      "policy/nn/hidden_1/weights/Assign\n",
      "policy/nn/hidden_1/weights/read\n",
      "policy/nn/hidden_1/biases\n",
      "policy/nn/hidden_1/biases/Initializer/random_normal/shape\n",
      "policy/nn/hidden_1/biases/Initializer/random_normal/mean\n",
      "policy/nn/hidden_1/biases/Initializer/random_normal/stddev\n",
      "policy/nn/hidden_1/biases/Initializer/random_normal/RandomStandardNormal\n",
      "policy/nn/hidden_1/biases/Initializer/random_normal/mul\n",
      "policy/nn/hidden_1/biases/Initializer/random_normal\n",
      "policy/nn/hidden_1/biases/Assign\n",
      "policy/nn/hidden_1/biases/read\n",
      "policy_1/nn/hidden_1/MatMul\n",
      "policy_1/nn/hidden_1/Add\n",
      "policy_1/nn/hidden_1/Relu\n",
      "policy_1/nn/hidden_1/HistogramSummary/tag\n",
      "policy_1/nn/hidden_1/HistogramSummary\n",
      "policy_1/nn/hidden_1/HistogramSummary_1/tag\n",
      "policy_1/nn/hidden_1/HistogramSummary_1\n",
      "policy_1/nn/hidden_1/HistogramSummary_2/tag\n",
      "policy_1/nn/hidden_1/HistogramSummary_2\n",
      "policy/nn/hidden_2/weights\n",
      "policy/nn/hidden_2/weights/Initializer/random_normal/shape\n",
      "policy/nn/hidden_2/weights/Initializer/random_normal/mean\n",
      "policy/nn/hidden_2/weights/Initializer/random_normal/stddev\n",
      "policy/nn/hidden_2/weights/Initializer/random_normal/RandomStandardNormal\n",
      "policy/nn/hidden_2/weights/Initializer/random_normal/mul\n",
      "policy/nn/hidden_2/weights/Initializer/random_normal\n",
      "policy/nn/hidden_2/weights/Assign\n",
      "policy/nn/hidden_2/weights/read\n",
      "policy/nn/hidden_2/biases\n",
      "policy/nn/hidden_2/biases/Initializer/random_normal/shape\n",
      "policy/nn/hidden_2/biases/Initializer/random_normal/mean\n",
      "policy/nn/hidden_2/biases/Initializer/random_normal/stddev\n",
      "policy/nn/hidden_2/biases/Initializer/random_normal/RandomStandardNormal\n",
      "policy/nn/hidden_2/biases/Initializer/random_normal/mul\n",
      "policy/nn/hidden_2/biases/Initializer/random_normal\n",
      "policy/nn/hidden_2/biases/Assign\n",
      "policy/nn/hidden_2/biases/read\n",
      "policy_1/nn/hidden_2/MatMul\n",
      "policy_1/nn/hidden_2/Add\n",
      "policy_1/nn/hidden_2/Relu\n",
      "policy_1/nn/hidden_2/HistogramSummary/tag\n",
      "policy_1/nn/hidden_2/HistogramSummary\n",
      "policy_1/nn/hidden_2/HistogramSummary_1/tag\n",
      "policy_1/nn/hidden_2/HistogramSummary_1\n",
      "policy_1/nn/hidden_2/HistogramSummary_2/tag\n",
      "policy_1/nn/hidden_2/HistogramSummary_2\n",
      "policy/nn/out/weights\n",
      "policy/nn/out/weights/Initializer/random_normal/shape\n",
      "policy/nn/out/weights/Initializer/random_normal/mean\n",
      "policy/nn/out/weights/Initializer/random_normal/stddev\n",
      "policy/nn/out/weights/Initializer/random_normal/RandomStandardNormal\n",
      "policy/nn/out/weights/Initializer/random_normal/mul\n",
      "policy/nn/out/weights/Initializer/random_normal\n",
      "policy/nn/out/weights/Assign\n",
      "policy/nn/out/weights/read\n",
      "policy/nn/out/biases\n",
      "policy/nn/out/biases/Initializer/random_normal/shape\n",
      "policy/nn/out/biases/Initializer/random_normal/mean\n",
      "policy/nn/out/biases/Initializer/random_normal/stddev\n",
      "policy/nn/out/biases/Initializer/random_normal/RandomStandardNormal\n",
      "policy/nn/out/biases/Initializer/random_normal/mul\n",
      "policy/nn/out/biases/Initializer/random_normal\n",
      "policy/nn/out/biases/Assign\n",
      "policy/nn/out/biases/read\n",
      "policy_1/nn/out/MatMul\n",
      "policy_1/nn/out/Add\n",
      "policy_1/nn/out/Softmax\n",
      "policy_1/nn/out/HistogramSummary/tag\n",
      "policy_1/nn/out/HistogramSummary\n",
      "policy_1/nn/out/HistogramSummary_1/tag\n",
      "policy_1/nn/out/HistogramSummary_1\n",
      "policy_1/nn/out/HistogramSummary_2/tag\n",
      "policy_1/nn/out/HistogramSummary_2\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "scope = 'policy'\n",
    "# NN_config = {'in': 10}\n",
    "NN_config = {'n_layers':3, \\\n",
    "             'in':784, \\\n",
    "\t\t\t 'hidden_1':256, \\\n",
    "\t\t\t 'hidden_2':256, \\\n",
    "\t\t\t 'out':10}\n",
    "# NN_config['in']\n",
    "p = MultiLayerNN_Policy(session=sess, optimizer=opt, scope=scope, NN_config=NN_config)\n",
    "# policy = Policy(session=sess, optimizer=opt, scope=scope, in_dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_all_trainable_vars():\n",
    "\tt_vars = tf.trainable_variables()\n",
    "\tfor i in xrange(len(t_vars)):\n",
    "\t\tprint(t_vars[i].name)\n",
    "\n",
    "def print_all_vars():\n",
    "\tall_vars = tf.all_variables()\n",
    "\tfor i in xrange(len(all_vars)):\n",
    "\t\tprint(all_vars[i].name)\n",
    "\n",
    "def print_ops(graph):\n",
    "\tops = graph.get_operations()\n",
    "\tfor i in xrange(len(ops)):\n",
    "\t\tprint(ops[i].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_ops(tf.get_default_graph())\n",
    "print_all_trainable_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ob = np.arange(10)\n",
    "ob = np.reshape(ob, (1,10))\n",
    "# policy.train(ob, 1, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
